{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Error Detection using K-means and Adaptive Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering positive entity vectors using k-means\n",
    "- Attempt to k-means clustering with an entity vector of triples consisting of <entity, type, person>.\n",
    "- A positive entity means that the entity is a person in the triple of <entity, type, person>.\n",
    "    - (e.g. entity : 'Biden', 'Trump', ...)\n",
    "- Find the maximum Euclidean distance between the centroid of each clusters and the elements included in the cluster.\n",
    "- The maximum Euclidean distance obtained from each cluster means the radius $r$ of the cluster, and entities located between the radius from the centroid are classified as entities of the cluster.\n",
    "\n",
    "## 2. Apply the adaptive clustering method.\n",
    "- Add the negative entity vector to the vector space clustered by the positive entity vector.\n",
    "- A negative entity means that the entity is not a person in the triple of <entity, type, person>.\n",
    "    - (e.g. entity : 'Titanic'(Film), 'New York'(City), ...)\n",
    "- Negative vectors are included in the cluster by calculating the distance between each centroid of the cluster.\n",
    "- Find the optimal $\\delta $(0.6 ~ 1.0) that will maximize the $f1-score$ of each cluster.\n",
    "- The $\\delta $ is multiplied by the cluster radius $r$ to create a new cluster range $r'$.\n",
    "    - $f1-score = \\frac{2\\times precision\\times recall}{precision+recall}$\n",
    "    - $precision = \\frac{TP}{TP+FP}$\n",
    "    - $recall = \\frac{TP}{TP+FN}$\n",
    "    - $TP(True Positive)$ = Number of positive entities included in the cluster  \n",
    "    - $FP(False Positive)$ = Number of negative entities included in the cluster\n",
    "    - $FN(False Negative)$ = The number of positive entities included in the cluster before the cluster range was adjusted but not included after the adjustment.  \n",
    "\n",
    "## 3. Perform error triple detection.\n",
    "- Add the positive and negative vectors of the test data to the vector space.\n",
    "- Apply a new radius $r'$ to each cluster multiplied by the optimal $\\delta $.\n",
    "- Entities included in the cluster are classified as positive entities, and entities not included in any cluster are classified as negative entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "from AdaClustering.ClusteringAlgorithm import kmeans_alg, grant_to_cluster\n",
    "from evaluation.metrics import get_initial_TP, get_ada_matrics, get_optimal_matrics\n",
    "from util.counter import count_element, count_TPFP\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob ,os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances  #k-means using euclidean_distances\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load skip-gram embedding vectors from model\n",
    "- dataname options :\n",
    "    - dbpedia / freebase / wisekb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_name options = freebase, dbpedia, wisekb\n",
    "dataname = 'freebase'\n",
    "k_dict = {'freebase' : 21, 'dbpedia' : 21, 'wiseKB' : 27}\n",
    "opt_k = k_dict[dataname]\n",
    "\n",
    "save_model_path = f'./data/SkipgramEntityVectors/skipgram_{dataname}_person'\n",
    "\n",
    "\"\"\"\n",
    "Word2VecKeyedVector object\n",
    "- key(string) : word\n",
    "- value(numpy array) : word vector\n",
    "\"\"\"\n",
    "keyedvectors = gensim.models.KeyedVectors.load_word2vec_format(save_model_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load entity label from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_positive contains 20000 entities\n",
      "['23899570', '49325820', '59159370', '49921652', '39747070'] \n",
      "\n",
      "train_negative contains 5000 entities\n",
      "['23490277', '58522601', '35716929', '55590744', '43009747'] \n",
      "\n",
      "test_positive contains 5000 entities\n",
      "['45555043', '45834103', '22467328', '58221651', '19409672'] \n",
      "\n",
      "test_negative contains 5000 entities\n",
      "['2507774', '5774863', '7240658', '57271678', '40535264'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if dataname=='freebase':\n",
    "    sep = '\\t'\n",
    "else:\n",
    "    sep = ' '\n",
    "    \n",
    "path = f'./data/{dataname}/'\n",
    "all_files = glob.glob(os.path.join(path, \"*.txt\"))    \n",
    "filename_list = ['train_positive', 'train_negative', 'test_positive', 'test_negative']\n",
    "train_pos_entities = []\n",
    "train_neg_entities = []\n",
    "test_pos_entities = []\n",
    "test_neg_entities = []\n",
    "all_entities = []\n",
    "for file_name in filename_list:\n",
    "    for directory in all_files:\n",
    "        if file_name in directory:\n",
    "            entities = []\n",
    "            data_name = file_name.split('/')[0]\n",
    "            with open(directory) as f:          \n",
    "                for triple in f:\n",
    "                    entities.append(triple.split(sep)[0].strip())\n",
    "            print(f'{data_name} contains {len(entities)} entities')\n",
    "            print(entities[:5], '\\n')\n",
    "            all_entities.append(entities)\n",
    "train_pos_entities, train_neg_entities, test_pos_entities, test_neg_entities = all_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering positive entity vectors using k-means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors, centroids, c_label = kmeans_alg(train_pos_entities, opt_k, keyedvectors)\n",
    "\n",
    "# dictionary for labeling entity with cluster - key : cluster label / - value : list of vectors\n",
    "dicts_each_cluster = {}\n",
    "for c in range(opt_k):\n",
    "    same_Cluster = []    \n",
    "    for idx, label in enumerate(c_label):\n",
    "        if label == c:\n",
    "            same_Cluster.append(vectors[idx].tolist())    \n",
    "    dicts_each_cluster[c]= list(same_Cluster)\n",
    "\n",
    "# dictionary for each cluster's max Euclidean distance \n",
    "max_distance_each_cluster = {}\n",
    "\n",
    "for i in dicts_each_cluster.keys():\n",
    "    in_vectors = dicts_each_cluster[i]\n",
    "    tmp_distance = euclidean_distances(in_vectors, centroids[i].reshape(1,-1))\n",
    "    \n",
    "    # max_distance_each_cluster - key : cluster lable / - value : max_distance\n",
    "    max_distance_each_cluster[i] = max(tmp_distance)[0].astype(np.float32) \n",
    "    \n",
    "# Get vectors from embedding model \n",
    "train_pos_vector = list(map(lambda x: (x, keyedvectors.word_vec(x)), train_pos_entities))\n",
    "train_neg_vector = list(map(lambda x: (x, keyedvectors.word_vec(x)), train_neg_entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Statistics before delta optimzing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_cluster_pos</th>\n",
       "      <th>initial_cluster_neg</th>\n",
       "      <th>initial_cluster_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380</td>\n",
       "      <td>40</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743</td>\n",
       "      <td>57</td>\n",
       "      <td>0.968333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>897</td>\n",
       "      <td>271</td>\n",
       "      <td>0.767979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1808</td>\n",
       "      <td>64</td>\n",
       "      <td>0.965812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>426</td>\n",
       "      <td>20</td>\n",
       "      <td>0.955157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_cluster_pos  initial_cluster_neg  initial_cluster_precision\n",
       "0                  380                   40                   0.904762\n",
       "1                 1743                   57                   0.968333\n",
       "2                  897                  271                   0.767979\n",
       "3                 1808                   64                   0.965812\n",
       "4                  426                   20                   0.955157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_cluster = grant_to_cluster(train_pos_vector, 1, max_distance_each_cluster, centroids)\n",
    "false_cluster = grant_to_cluster(train_neg_vector, 1, max_distance_each_cluster, centroids)\n",
    "true_count, false_count = count_TPFP(centroids, true_cluster, false_cluster)\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# 각 클러스터에 포함된 positive 엔티티, negative 엔티티수로 각 클러스터에 대한 precision 지표 산출\n",
    "for cluster in range(len(centroids)):\n",
    "    TP = true_count[cluster] # True Positive : 클러스터 포함되어있는 positive 엔티티\n",
    "    FP = false_count[cluster] # False Positive : 클러스터에 포함되어있는 negative 엔티티\n",
    "    if (TP+FP) == 0:\n",
    "        precision = 0.0\n",
    "    else:\n",
    "        precision = TP / (TP+FP)\n",
    "    result_list.append([TP,FP,precision])\n",
    "\n",
    "# first_result_df\n",
    "pre_result_df = pd.DataFrame(result_list, columns=['initial_cluster_pos', \n",
    "                                                   'initial_cluster_neg', \n",
    "                                                   'initial_cluster_precision'])\n",
    "pre_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply the adaptive clustering method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimize delta for each clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimaldeltas each clusters : \n",
      " [0.82 0.68 0.73 0.68 0.93 0.68 0.81 0.74 0.82 0.68 0.68 0.85 0.9  0.93\n",
      " 0.7  0.77 0.6  0.7  0.85 0.68 1.  ]\n"
     ]
    }
   ],
   "source": [
    "P, R, F1, TP, FN, FP, initial_TP = get_ada_matrics(train_pos_vector, train_neg_vector, \n",
    "                                                   max_distance_each_cluster, centroids)\n",
    "\n",
    "\n",
    "TP_list = TP[np.array(F1).argmax(0),list(range(TP.shape[1]))]\n",
    "\n",
    "#cluster의 f1 score가 최대가 되는 지점의 delta를 optimal delta로 선정\n",
    "optimal_deltas = np.array(F1).argmax(0)\n",
    "optimal_deltas = (optimal_deltas * 0.01)+0.6\n",
    "\n",
    "# positive entity수가 0인 cluster는 delta를 0으로 변환\n",
    "optimal_deltas = np.array([d if tp != 0 else 0 for d, tp in zip(optimal_deltas, TP_list)])\n",
    "\n",
    "print('optimaldeltas each clusters : \\n', optimal_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_cluster_pos</th>\n",
       "      <th>initial_cluster_neg</th>\n",
       "      <th>initial_cluster_precision</th>\n",
       "      <th>opt_delta</th>\n",
       "      <th>opt_TP</th>\n",
       "      <th>opt_FP</th>\n",
       "      <th>opt_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380</td>\n",
       "      <td>40</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.82</td>\n",
       "      <td>370</td>\n",
       "      <td>21</td>\n",
       "      <td>0.946292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743</td>\n",
       "      <td>57</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>897</td>\n",
       "      <td>271</td>\n",
       "      <td>0.767979</td>\n",
       "      <td>0.73</td>\n",
       "      <td>825</td>\n",
       "      <td>100</td>\n",
       "      <td>0.891892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1808</td>\n",
       "      <td>64</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1781</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>426</td>\n",
       "      <td>20</td>\n",
       "      <td>0.955157</td>\n",
       "      <td>0.93</td>\n",
       "      <td>425</td>\n",
       "      <td>12</td>\n",
       "      <td>0.972540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_cluster_pos  initial_cluster_neg  initial_cluster_precision  \\\n",
       "0                  380                   40                   0.904762   \n",
       "1                 1743                   57                   0.968333   \n",
       "2                  897                  271                   0.767979   \n",
       "3                 1808                   64                   0.965812   \n",
       "4                  426                   20                   0.955157   \n",
       "\n",
       "   opt_delta  opt_TP  opt_FP  opt_precision  \n",
       "0       0.82     370      21       0.946292  \n",
       "1       0.68    1715       0       1.000000  \n",
       "2       0.73     825     100       0.891892  \n",
       "3       0.68    1781       2       0.998878  \n",
       "4       0.93     425      12       0.972540  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 구한 optimal delta를 cluster에 적용하여 각 cluster에 대한 precision, recall, TP, FP를 산출\n",
    "optimalP, optimalR, optimalTP, optimalFP = get_optimal_matrics(train_pos_vector, train_neg_vector, \n",
    "                                                            max_distance_each_cluster,centroids, \n",
    "                                                            optimal_deltas, initial_TP)\n",
    "\n",
    "matrics = []\n",
    "for m1, m2, m3, m4, m5 in zip(optimalP, optimalR,  optimalTP, optimalFP, optimal_deltas):\n",
    "    matrics.append([m1, m2, m3, m4, m5])\n",
    "    \n",
    "opt_delta_df = pd.DataFrame(matrics, columns=['opt_precision', 'opt_recall', 'opt_TP','opt_FP', 'opt_delta'])\n",
    "tmp_parse_df = opt_delta_df[['opt_delta','opt_TP','opt_FP', 'opt_precision']]\n",
    "train_result_df = pd.concat([pre_result_df, tmp_parse_df], axis = 1)\n",
    "train_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform error triple detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test vectors from embedding model \n",
    "test_pos_vector = list(map(lambda x: (x, keyedvectors.word_vec(x)), test_pos_entities))\n",
    "test_neg_vector = list(map(lambda x: (x, keyedvectors.word_vec(x)), test_neg_entities))\n",
    "initial_TP = get_initial_TP(test_pos_vector, max_distance_each_cluster, centroids)\n",
    "\n",
    "# test 데이터의 embedding 벡터를 cluster에 할당하여 Precision, Recall 산출\n",
    "optimalP, optimalR, optimalTP, optimalFP = get_optimal_matrics(test_pos_vector, test_neg_vector, \n",
    "                                                               max_distance_each_cluster, centroids, \n",
    "                                                               optimal_deltas, initial_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_cluster_pos</th>\n",
       "      <th>initial_cluster_neg</th>\n",
       "      <th>initial_cluster_precision</th>\n",
       "      <th>opt_delta</th>\n",
       "      <th>opt_TP</th>\n",
       "      <th>opt_FP</th>\n",
       "      <th>opt_precision</th>\n",
       "      <th>Test_TP</th>\n",
       "      <th>Test_FP</th>\n",
       "      <th>Test_precision</th>\n",
       "      <th>Test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380</td>\n",
       "      <td>40</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.82</td>\n",
       "      <td>370</td>\n",
       "      <td>21</td>\n",
       "      <td>0.946292</td>\n",
       "      <td>101</td>\n",
       "      <td>20</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.901786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743</td>\n",
       "      <td>57</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>362</td>\n",
       "      <td>47</td>\n",
       "      <td>0.885086</td>\n",
       "      <td>0.952632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>897</td>\n",
       "      <td>271</td>\n",
       "      <td>0.767979</td>\n",
       "      <td>0.73</td>\n",
       "      <td>825</td>\n",
       "      <td>100</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>227</td>\n",
       "      <td>146</td>\n",
       "      <td>0.608579</td>\n",
       "      <td>0.893701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1808</td>\n",
       "      <td>64</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1781</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998878</td>\n",
       "      <td>454</td>\n",
       "      <td>101</td>\n",
       "      <td>0.818018</td>\n",
       "      <td>0.984816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>426</td>\n",
       "      <td>20</td>\n",
       "      <td>0.955157</td>\n",
       "      <td>0.93</td>\n",
       "      <td>425</td>\n",
       "      <td>12</td>\n",
       "      <td>0.972540</td>\n",
       "      <td>112</td>\n",
       "      <td>21</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_cluster_pos  initial_cluster_neg  initial_cluster_precision  \\\n",
       "0                  380                   40                   0.904762   \n",
       "1                 1743                   57                   0.968333   \n",
       "2                  897                  271                   0.767979   \n",
       "3                 1808                   64                   0.965812   \n",
       "4                  426                   20                   0.955157   \n",
       "\n",
       "   opt_delta  opt_TP  opt_FP  opt_precision  Test_TP  Test_FP  Test_precision  \\\n",
       "0       0.82     370      21       0.946292      101       20        0.834711   \n",
       "1       0.68    1715       0       1.000000      362       47        0.885086   \n",
       "2       0.73     825     100       0.891892      227      146        0.608579   \n",
       "3       0.68    1781       2       0.998878      454      101        0.818018   \n",
       "4       0.93     425      12       0.972540      112       21        0.842105   \n",
       "\n",
       "   Test_recall  \n",
       "0     0.901786  \n",
       "1     0.952632  \n",
       "2     0.893701  \n",
       "3     0.984816  \n",
       "4     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrics = []\n",
    "for m1, m2, m3, m4, m5 in zip(optimalP, optimalR, optimalTP, optimalFP, optimal_deltas):\n",
    "    matrics.append([m1, m2, m3, m4, m5])\n",
    "    \n",
    "output_df = pd.DataFrame(matrics, columns=['precision', 'recall', 'TP','FP', 'delta'])\n",
    "tmp_output_df = output_df[['TP','FP', 'precision', 'recall']]\n",
    "tmp_output_df.columns = ['Test_TP','Test_FP', 'Test_precision', 'Test_recall']\n",
    "\n",
    "train_test_df = pd.concat([train_result_df, tmp_output_df], axis = 1)\n",
    "train_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP : 4728\n",
      "FP : 1508\n",
      "precision : 0.758\n",
      "recall : 0.946\n",
      "F1 : 0.842\n",
      "\n",
      "Detected 3492 error triples\n",
      "Detected 272 normal triples as error triples\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대한 error detection결과 및 precision, recall, F1 score 산출\n",
    "test_TP = sum(train_test_df['Test_TP'].values)\n",
    "test_FP = sum(train_test_df['Test_FP'].values)\n",
    "\n",
    "test_precision = test_TP / (test_TP + test_FP)\n",
    "test_recall = test_TP / len(test_pos_entities)\n",
    "test_f1 = (2*test_precision*test_recall) / (test_precision+test_recall)\n",
    "\n",
    "print(f'TP : {test_TP}')\n",
    "print(f'FP : {test_FP}')\n",
    "print(f'precision : {test_precision:.3f}')\n",
    "print(f'recall : {test_recall:.3f}')\n",
    "print(f'F1 : {test_f1:.3f}')\n",
    "\n",
    "print(f'\\nDetected {len(test_neg_entities) - test_FP} error triples')\n",
    "print(f'Detected {len(test_pos_entities)-test_TP} normal triples as error triples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

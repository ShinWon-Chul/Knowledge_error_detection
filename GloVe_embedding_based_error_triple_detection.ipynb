{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Error Detection using K-means and Adaptive Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering positive entity vectors using k-means\n",
    "- Attempt to k-means clustering with an entity vector of triples consisting of <entity, type, person>.\n",
    "- A positive entity means that the entity is a person in the triple of <entity, type, person>.\n",
    "    - (e.g. entity : 'Biden', 'Trump', ...)\n",
    "- Find the maximum Euclidean distance between the centroid of each clusters and the elements included in the cluster.\n",
    "- The maximum Euclidean distance obtained from each cluster means the radius $r$ of the cluster, and entities located between the radius from the centroid are classified as entities of the cluster.\n",
    "\n",
    "## 2. Apply the adaptive clustering method.\n",
    "- Add the negative entity vector to the vector space clustered by the positive entity vector.\n",
    "- A negative entity means that the entity is not a person in the triple of <entity, type, person>.\n",
    "    - (e.g. entity : 'Titanic'(Film), 'New York'(City), ...)\n",
    "- Negative vectors are included in the cluster by calculating the distance between each centroid of the cluster.\n",
    "- Find the optimal $\\delta $(0.6 ~ 1.0) that will maximize the $f1-score$ of each cluster.\n",
    "- The $\\delta $ is multiplied by the cluster radius $r$ to create a new cluster range $r'$.\n",
    "    - $f1-score = \\frac{2\\times precision\\times recall}{precision+recall}$\n",
    "    - $precision = \\frac{TP}{TP+FP}$\n",
    "    - $recall = \\frac{TP}{TP+FN}$\n",
    "    - $TP(True Positive)$ = Number of positive entities included in the cluster  \n",
    "    - $FP(False Positive)$ = Number of negative entities included in the cluster\n",
    "    - $FN(False Negative)$ = The number of positive entities included in the cluster before the cluster range was adjusted but not included after the adjustment.  \n",
    "\n",
    "## 3. Perform error triple detection.\n",
    "- Add the positive and negative vectors of the test data to the vector space.\n",
    "- Apply a new radius $r'$ to each cluster multiplied by the optimal $\\delta $.\n",
    "- Entities included in the cluster are classified as positive entities, and entities not included in any cluster are classified as negative entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "from AdaClustering.ClusteringAlgorithm import kmeans_alg, grant_to_cluster\n",
    "from evaluation.metrics import get_initial_TP, get_ada_matrics, get_optimal_matrics\n",
    "from util.counter import count_element, count_TPFP\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances  #k-means using euclidean_distances\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe embedding vectors from file\n",
    "- dataname options :\n",
    "    - dbpedia / freebase / wisekb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50664\n"
     ]
    }
   ],
   "source": [
    "dataname = 'dbpedia'\n",
    "k_dict = {'freebase' : 46, 'dbpedia' : 15, 'wiseKB' : 27}\n",
    "\n",
    "opt_k = k_dict[dataname]\n",
    "\n",
    "f = open(f'./data/GloVeEntityVectors/glove_{dataname}/person_embedding','rb')\n",
    "vector = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "\n",
    "f = open(f'./data/GloVeEntityVectors/glove_{dataname}/person_words','rb')\n",
    "word = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    " \n",
    "glove_dict = {}\n",
    "for i in range(len(vector)):\n",
    "    glove_dict[word[i]] = vector[i]\n",
    "    \n",
    "print(len(glove_dict)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load entity label from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pos :  20000\n",
      "['e_2398311', 'e_4856915', 'e_375534', 'e_401503', 'e_1890861']\n",
      "\n",
      "train_neg :  5000\n",
      "['e_2022579', 'e_4008488', 'e_1863291', 'e_96735', 'e_2223783']\n",
      "\n",
      "test_pos :  5000\n",
      "['e_1089098', 'e_4119140', 'e_2066827', 'e_1183621', 'e_1708557']\n",
      "\n",
      "test_neg :  5000\n",
      "['e_1629807', 'e_2163227', 'e_5848230', 'e_2079695', 'e_1725594']\n"
     ]
    }
   ],
   "source": [
    "label_dir = f'./data/{dataname}/'\n",
    "\n",
    "train_pos_loc = label_dir + 'train_positive_20000.txt'\n",
    "train_neg_loc = label_dir + 'train_negative_5000.txt'\n",
    "test_pos_loc = label_dir + 'test_positive_5000.txt'\n",
    "test_neg_loc = label_dir + 'test_negative_5000.txt'\n",
    "\n",
    "train_pos_embedding = []\n",
    "train_neg_embedding = []\n",
    "test_pos_embedding = []\n",
    "test_neg_embedding = []\n",
    "\n",
    "if dataname=='freebase':\n",
    "    sep = '\\t'\n",
    "else:\n",
    "    sep = ' '\n",
    "    \n",
    "with open(train_pos_loc) as f:          \n",
    "    for i in f:\n",
    "        train_pos_embedding.append(i.split(sep)[0].strip())\n",
    "        \n",
    "print('train_pos : ',len(train_pos_embedding))\n",
    "print(train_pos_embedding[:5])\n",
    "\n",
    "with open(train_neg_loc) as f:          \n",
    "    for i in f:\n",
    "        train_neg_embedding.append(i.split(sep)[0].strip())\n",
    "        \n",
    "print('\\ntrain_neg : ',len(train_neg_embedding))\n",
    "print(train_neg_embedding[:5])\n",
    "\n",
    "with open(test_pos_loc) as f:       \n",
    "    for i in f:\n",
    "        test_pos_embedding.append(i.split(sep)[0].strip())\n",
    "        \n",
    "print('\\ntest_pos : ',len(test_pos_embedding))\n",
    "print(test_pos_embedding[:5])\n",
    "\n",
    "with open(test_neg_loc) as f:\n",
    "    for i in f:\n",
    "        test_neg_embedding.append(i.split(sep)[0].strip())\n",
    "        \n",
    "print('\\ntest_neg : ',len(test_neg_embedding))\n",
    "print(test_neg_embedding[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering positive entity vectors using k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors, centroids, c_label = kmeans_alg(train_pos_embedding, opt_k, glove_dict)\n",
    "\n",
    "# dictionary for labeling entity with cluster - key : cluster label / - value : list of vectors\n",
    "dicts_each_cluster = {}\n",
    "for c in range(opt_k):\n",
    "    same_Cluster = []    \n",
    "    for idx, label in enumerate(c_label):\n",
    "        if label == c:\n",
    "            same_Cluster.append(vectors[idx].tolist())    \n",
    "    dicts_each_cluster[c]= list(same_Cluster)\n",
    "\n",
    "# dictionary for each cluster's max Euclidean distance \n",
    "max_distance_each_cluster = {}\n",
    "\n",
    "for i in dicts_each_cluster.keys():\n",
    "    in_vectors = dicts_each_cluster[i] \n",
    "    tmp_distance = euclidean_distances(in_vectors, centroids[i].reshape(1,-1))\n",
    "    \n",
    "    # max_distance_each_cluster - key : cluster lable / - value : max_distance\n",
    "    max_distance_each_cluster[i] = max(tmp_distance)[0].astype(np.float32) \n",
    "    \n",
    "# Get vectors \n",
    "train_pos_vector = list(map(lambda x: (x,glove_dict[x]), train_pos_embedding)) # [(word, vector), ... (word, vector)]\n",
    "train_neg_vector = list(map(lambda x: (x,glove_dict[x]), train_neg_embedding)) # [(word, vector), ... (word, vector)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Statistics before delta optimzing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_cluster_pos</th>\n",
       "      <th>initial_cluster_neg</th>\n",
       "      <th>initial_cluster_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1401</td>\n",
       "      <td>248</td>\n",
       "      <td>0.849606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1547</td>\n",
       "      <td>92</td>\n",
       "      <td>0.943868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1343</td>\n",
       "      <td>265</td>\n",
       "      <td>0.835199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1298</td>\n",
       "      <td>211</td>\n",
       "      <td>0.860172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1401</td>\n",
       "      <td>280</td>\n",
       "      <td>0.833432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_cluster_pos  initial_cluster_neg  initial_cluster_precision\n",
       "0                 1401                  248                   0.849606\n",
       "1                 1547                   92                   0.943868\n",
       "2                 1343                  265                   0.835199\n",
       "3                 1298                  211                   0.860172\n",
       "4                 1401                  280                   0.833432"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_cluster = grant_to_cluster(train_pos_vector, 1, max_distance_each_cluster, centroids)\n",
    "false_cluster = grant_to_cluster(train_neg_vector, 1, max_distance_each_cluster, centroids)\n",
    "true_count, false_count = count_TPFP(centroids, true_cluster, false_cluster)\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# 각 클러스터에 포함된 positive 엔티티, negative 엔티티수로 각 클러스터에 대한 precision 지표 산출\n",
    "for cluster in range(len(centroids)):\n",
    "    TP = true_count[cluster] # True Positive : 클러스터 포함되어있는 positive 엔티티\n",
    "    FP = false_count[cluster] # False Positive : 클러스터에 포함되어있는 negative 엔티티\n",
    "    if (TP+FP) == 0:\n",
    "        precision = 0.0\n",
    "    else:\n",
    "        precision = TP / (TP+FP)\n",
    "    result_list.append([TP,FP,precision])\n",
    "\n",
    "# first_result_df\n",
    "pre_result_df = pd.DataFrame(result_list, columns=['initial_cluster_pos', \n",
    "                                                   'initial_cluster_neg', \n",
    "                                                   'initial_cluster_precision'])\n",
    "pre_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply the adaptive clustering method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimize delta for each clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimaldeltas each clusters : \n",
      " [0.98 1.   1.   0.96 0.9  1.   0.93 0.96 1.   1.   0.97 0.99 1.   1.\n",
      " 0.95]\n"
     ]
    }
   ],
   "source": [
    "P, R, F1, TP, FN, FP, initial_TP = get_ada_matrics(train_pos_vector, train_neg_vector, \n",
    "                                                   max_distance_each_cluster, centroids)\n",
    "\n",
    "\n",
    "TP_list = TP[np.array(F1).argmax(0),list(range(TP.shape[1]))]\n",
    "\n",
    "#cluster의 f1 score가 최대가 되는 지점의 delta를 optimal delta로 선정\n",
    "optimal_deltas = np.array(F1).argmax(0)\n",
    "optimal_deltas = (optimal_deltas * 0.01)+0.6\n",
    "\n",
    "# positive entity수가 0인 cluster는 delta를 0으로 변환\n",
    "optimal_deltas = np.array([d if tp != 0 else 0 for d, tp in zip(optimal_deltas, TP_list)])\n",
    "\n",
    "print('optimaldeltas each clusters : \\n', optimal_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_cluster_pos</th>\n",
       "      <th>initial_cluster_neg</th>\n",
       "      <th>initial_cluster_precision</th>\n",
       "      <th>opt_delta</th>\n",
       "      <th>opt_TP</th>\n",
       "      <th>opt_FP</th>\n",
       "      <th>opt_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1401</td>\n",
       "      <td>248</td>\n",
       "      <td>0.849606</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1399</td>\n",
       "      <td>245</td>\n",
       "      <td>0.850973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1547</td>\n",
       "      <td>92</td>\n",
       "      <td>0.943868</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1547</td>\n",
       "      <td>92</td>\n",
       "      <td>0.943868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1343</td>\n",
       "      <td>265</td>\n",
       "      <td>0.835199</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1343</td>\n",
       "      <td>265</td>\n",
       "      <td>0.835199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1298</td>\n",
       "      <td>211</td>\n",
       "      <td>0.860172</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1295</td>\n",
       "      <td>207</td>\n",
       "      <td>0.862184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1401</td>\n",
       "      <td>280</td>\n",
       "      <td>0.833432</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1399</td>\n",
       "      <td>276</td>\n",
       "      <td>0.835224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_cluster_pos  initial_cluster_neg  initial_cluster_precision  \\\n",
       "0                 1401                  248                   0.849606   \n",
       "1                 1547                   92                   0.943868   \n",
       "2                 1343                  265                   0.835199   \n",
       "3                 1298                  211                   0.860172   \n",
       "4                 1401                  280                   0.833432   \n",
       "\n",
       "   opt_delta  opt_TP  opt_FP  opt_precision  \n",
       "0       0.98    1399     245       0.850973  \n",
       "1       1.00    1547      92       0.943868  \n",
       "2       1.00    1343     265       0.835199  \n",
       "3       0.96    1295     207       0.862184  \n",
       "4       0.90    1399     276       0.835224  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 구한 optimal delta를 cluster에 적용하여 각 cluster에 대한 precision, recall, TP, FP를 산출\n",
    "optimalP, optimalR, optimalTP, optimalFP = get_optimal_matrics(train_pos_vector, train_neg_vector, \n",
    "                                                               max_distance_each_cluster,centroids, \n",
    "                                                               optimal_deltas, initial_TP)\n",
    "\n",
    "matrics = []\n",
    "for m1, m2, m3, m4, m5 in zip(optimalP, optimalR,  optimalTP, optimalFP, optimal_deltas):\n",
    "    matrics.append([m1, m2, m3, m4, m5])\n",
    "    \n",
    "opt_delta_df = pd.DataFrame(matrics, columns=['opt_precision', 'opt_recall', 'opt_TP','opt_FP', 'opt_delta'])\n",
    "tmp_parse_df = opt_delta_df[['opt_delta','opt_TP','opt_FP', 'opt_precision']]\n",
    "train_result_df = pd.concat([pre_result_df, tmp_parse_df], axis = 1)\n",
    "train_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Error triple detection using test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test vectors from embedding model \n",
    "test_pos_vector = list(map(lambda x: (x,glove_dict[x]), test_pos_embedding))\n",
    "test_neg_vector = list(map(lambda x: (x,glove_dict[x]), test_neg_embedding))\n",
    "initial_TP = get_initial_TP(test_pos_vector, max_distance_each_cluster, centroids)\n",
    "\n",
    "# test 데이터의 embedding 벡터를 cluster에 할당하여 Precision, Recall 산출\n",
    "optimalP, optimalR, optimalTP, optimalFP = get_optimal_matrics(test_pos_vector, test_neg_vector, \n",
    "                                                               max_distance_each_cluster, centroids, \n",
    "                                                               optimal_deltas, initial_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_cluster_pos</th>\n",
       "      <th>initial_cluster_neg</th>\n",
       "      <th>initial_cluster_precision</th>\n",
       "      <th>opt_delta</th>\n",
       "      <th>opt_TP</th>\n",
       "      <th>opt_FP</th>\n",
       "      <th>opt_precision</th>\n",
       "      <th>Test_TP</th>\n",
       "      <th>Test_FP</th>\n",
       "      <th>Test_precision</th>\n",
       "      <th>Test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1401</td>\n",
       "      <td>248</td>\n",
       "      <td>0.849606</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1399</td>\n",
       "      <td>245</td>\n",
       "      <td>0.850973</td>\n",
       "      <td>345</td>\n",
       "      <td>262</td>\n",
       "      <td>0.568369</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1547</td>\n",
       "      <td>92</td>\n",
       "      <td>0.943868</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1547</td>\n",
       "      <td>92</td>\n",
       "      <td>0.943868</td>\n",
       "      <td>392</td>\n",
       "      <td>100</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1343</td>\n",
       "      <td>265</td>\n",
       "      <td>0.835199</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1343</td>\n",
       "      <td>265</td>\n",
       "      <td>0.835199</td>\n",
       "      <td>348</td>\n",
       "      <td>237</td>\n",
       "      <td>0.594872</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1298</td>\n",
       "      <td>211</td>\n",
       "      <td>0.860172</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1295</td>\n",
       "      <td>207</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>292</td>\n",
       "      <td>190</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>0.993197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1401</td>\n",
       "      <td>280</td>\n",
       "      <td>0.833432</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1399</td>\n",
       "      <td>276</td>\n",
       "      <td>0.835224</td>\n",
       "      <td>347</td>\n",
       "      <td>271</td>\n",
       "      <td>0.561489</td>\n",
       "      <td>0.994269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_cluster_pos  initial_cluster_neg  initial_cluster_precision  \\\n",
       "0                 1401                  248                   0.849606   \n",
       "1                 1547                   92                   0.943868   \n",
       "2                 1343                  265                   0.835199   \n",
       "3                 1298                  211                   0.860172   \n",
       "4                 1401                  280                   0.833432   \n",
       "\n",
       "   opt_delta  opt_TP  opt_FP  opt_precision  Test_TP  Test_FP  Test_precision  \\\n",
       "0       0.98    1399     245       0.850973      345      262        0.568369   \n",
       "1       1.00    1547      92       0.943868      392      100        0.796748   \n",
       "2       1.00    1343     265       0.835199      348      237        0.594872   \n",
       "3       0.96    1295     207       0.862184      292      190        0.605809   \n",
       "4       0.90    1399     276       0.835224      347      271        0.561489   \n",
       "\n",
       "   Test_recall  \n",
       "0     1.000000  \n",
       "1     1.000000  \n",
       "2     1.000000  \n",
       "3     0.993197  \n",
       "4     0.994269  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrics = []\n",
    "for m1, m2, m3, m4, m5 in zip(optimalP, optimalR, optimalTP, optimalFP, optimal_deltas):\n",
    "    matrics.append([m1, m2, m3, m4, m5])\n",
    "    \n",
    "output_df = pd.DataFrame(matrics, columns=['precision', 'recall', 'TP','FP', 'delta'])\n",
    "tmp_output_df = output_df[['TP','FP', 'precision', 'recall']]\n",
    "tmp_output_df.columns = ['Test_TP','Test_FP', 'Test_precision', 'Test_recall']\n",
    "\n",
    "train_test_df = pd.concat([train_result_df, tmp_output_df], axis = 1)\n",
    "train_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP :  4991\n",
      "FP :  4936\n",
      "precision :  0.5027702226251637\n",
      "recall :  0.9982\n",
      "F1 :  0.6687211093990754\n",
      "\n",
      "Detected 64 error triples\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대한 error detection결과 및 precision, recall, F1 score 산출\n",
    "new_TP = sum(train_test_df['Test_TP'].values)\n",
    "new_FP = sum(train_test_df['Test_FP'].values)\n",
    "\n",
    "new_precision = new_TP / (new_TP + new_FP)\n",
    "new_recall = new_TP / len(test_pos_embedding)\n",
    "new_f1 = (2*new_precision*new_recall) / (new_precision+new_recall)\n",
    "\n",
    "print('TP : ', new_TP)\n",
    "print('FP : ', new_FP)\n",
    "print('precision : ', new_precision)\n",
    "print('recall : ', new_recall)\n",
    "print('F1 : ', new_f1)\n",
    "\n",
    "print(f'\\nDetected {len(test_neg_embedding) - new_FP} error triples')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

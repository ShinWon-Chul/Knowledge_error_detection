{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Error Detection using K-means and Adaptive Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering positive entity vectors using k-means\n",
    "- Attempt to k-means clustering with an entity vector of triples consisting of <entity, type, person>.\n",
    "- A positive entity means that the entity is a person in the triple of <entity, type, person>.\n",
    "    - (e.g. entity : 'Biden', 'Trump', ...)\n",
    "- Find the maximum Euclidean distance between the centroid of each clusters and the elements included in the cluster.\n",
    "- The maximum Euclidean distance obtained from each cluster means the radius $r$ of the cluster, and entities located between the radius from the centroid are classified as entities of the cluster.\n",
    "\n",
    "## 2. Apply the adaptive clustering method.\n",
    "- Add the negative entity vector to the vector space clustered by the positive entity vector.\n",
    "- A negative entity means that the entity is not a person in the triple of <entity, type, person>.\n",
    "    - (e.g. entity : 'Titanic'(Film), 'New York'(City), ...)\n",
    "- Negative vectors are included in the cluster by calculating the distance between each centroid of the cluster.\n",
    "- Find the optimal $\\delta $(0.6 ~ 1.0) that will maximize the $f1-score$ of each cluster.\n",
    "- The $\\delta $ is multiplied by the cluster radius $r$ to create a new cluster range $r'$.\n",
    "    - $f1-score = \\frac{2\\times precision\\times recall}{precision+recall}$\n",
    "    - $precision = \\frac{TP}{TP+FP}$\n",
    "    - $recall = \\frac{TP}{TP+FN}$\n",
    "    - $TP(True Positive)$ = Number of positive entities included in the cluster  \n",
    "    - $FP(False Positive)$ = Number of negative entities included in the cluster\n",
    "    - $FN(False Negative)$ = The number of positive entities included in the cluster before the cluster range was adjusted but not included after the adjustment.  \n",
    "\n",
    "## 3. Perform error triple detection.\n",
    "- Add the positive and negative vectors of the test data to the vector space.\n",
    "- Apply a new radius $r'$ to each cluster multiplied by the optimal $\\delta $.\n",
    "- Entities included in the cluster are classified as positive entities, and entities not included in any cluster are classified as negative entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "from AdaClustering.ClusteringAlgorithm import kmeans_alg, grant_to_cluster\n",
    "from evaluation.metrics import get_initial_TP, get_ada_matrics, get_optimal_matrics\n",
    "from util.counter import count_element, count_TPFP\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances  #k-means using euclidean_distances\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe embedding vectors from file\n",
    "- dataname options :\n",
    "    - dbpedia / freebase / wisekb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50950\n"
     ]
    }
   ],
   "source": [
    "dataname = 'freebase'\n",
    "k_dict = {'freebase' : 11, 'dbpedia' : 15, 'wiseKB' : 27}\n",
    "\n",
    "opt_k = k_dict[dataname]\n",
    "\n",
    "f = open(f'./data/GloVeEntityVectors/glove_{dataname}/person_embedding 2','rb')\n",
    "vector = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "\n",
    "f = open(f'./data/GloVeEntityVectors/glove_{dataname}/person_words 2','rb')\n",
    "word = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    " \n",
    "glove_dict = {}\n",
    "for i in range(len(vector)):\n",
    "    glove_dict[word[i]] = vector[i]\n",
    "    \n",
    "print(len(glove_dict)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load entity label from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pos :  20000\n",
      "['23899570', '49325820', '59159370', '49921652', '39747070']\n",
      "\n",
      "train_neg :  5000\n",
      "['23490277', '58522601', '35716929', '55590744', '43009747']\n",
      "\n",
      "test_pos :  5000\n",
      "['45555043', '45834103', '22467328', '58221651', '19409672']\n",
      "\n",
      "test_neg :  5000\n",
      "['2507774', '5774863', '7240658', '57271678', '40535264']\n"
     ]
    }
   ],
   "source": [
    "label_dir = f'./data/{dataname}/'\n",
    "\n",
    "train_pos_loc = label_dir + 'train_positive_20000.txt'\n",
    "train_neg_loc = label_dir + 'train_negative_5000.txt'\n",
    "test_pos_loc = label_dir + 'test_positive_5000.txt'\n",
    "test_neg_loc = label_dir + 'test_negative_5000.txt'\n",
    "\n",
    "train_pos_embedding = []\n",
    "train_neg_embedding = []\n",
    "test_pos_embedding = []\n",
    "test_neg_embedding = []\n",
    "\n",
    "if dataname=='freebase':\n",
    "    sep = '\\t'\n",
    "else:\n",
    "    sep = ' '\n",
    "    \n",
    "with open(train_pos_loc) as f:          \n",
    "    for i in f:\n",
    "        train_pos_embedding.append(i.split(sep)[0].strip())\n",
    "        \n",
    "print('train_pos : ',len(train_pos_embedding))\n",
    "print(train_pos_embedding[:5])\n",
    "\n",
    "with open(train_neg_loc) as f:          \n",
    "    for i in f:\n",
    "        train_neg_embedding.append(i.split(sep)[0].strip())\n",
    "        \n",
    "print('\\ntrain_neg : ',len(train_neg_embedding))\n",
    "print(train_neg_embedding[:5])\n",
    "\n",
    "with open(test_pos_loc) as f:       \n",
    "    for i in f:\n",
    "        test_pos_embedding.append(i.split(sep)[0].strip())\n",
    "        \n",
    "print('\\ntest_pos : ',len(test_pos_embedding))\n",
    "print(test_pos_embedding[:5])\n",
    "\n",
    "with open(test_neg_loc) as f:\n",
    "    for i in f:\n",
    "        test_neg_embedding.append(i.split(sep)[0].strip())\n",
    "        \n",
    "print('\\ntest_neg : ',len(test_neg_embedding))\n",
    "print(test_neg_embedding[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering positive entity vectors using k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors, centroids, c_label = kmeans_alg(train_pos_embedding, opt_k, glove_dict)\n",
    "\n",
    "# dictionary for labeling entity with cluster - key : cluster label / - value : list of vectors\n",
    "dicts_each_cluster = {}\n",
    "for c in range(opt_k):\n",
    "    same_Cluster = []    \n",
    "    for idx, label in enumerate(c_label):\n",
    "        if label == c:\n",
    "            same_Cluster.append(vectors[idx].tolist())    \n",
    "    dicts_each_cluster[c]= list(same_Cluster)\n",
    "\n",
    "# dictionary for each cluster's max Euclidean distance \n",
    "max_distance_each_cluster = {}\n",
    "\n",
    "for i in dicts_each_cluster.keys():\n",
    "    in_vectors = dicts_each_cluster[i] \n",
    "    tmp_distance = euclidean_distances(in_vectors, centroids[i].reshape(1,-1))\n",
    "    \n",
    "    # max_distance_each_cluster - key : cluster lable / - value : max_distance\n",
    "    max_distance_each_cluster[i] = max(tmp_distance)[0].astype(np.float32) \n",
    "    \n",
    "# Get vectors \n",
    "train_pos_vector = list(map(lambda x: (x,glove_dict[x]), train_pos_embedding)) # [(word, vector), ... (word, vector)]\n",
    "train_neg_vector = list(map(lambda x: (x,glove_dict[x]), train_neg_embedding)) # [(word, vector), ... (word, vector)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Statistics before delta optimzing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_cluster_pos</th>\n",
       "      <th>initial_cluster_neg</th>\n",
       "      <th>initial_cluster_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>626</td>\n",
       "      <td>26</td>\n",
       "      <td>0.960123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842</td>\n",
       "      <td>350</td>\n",
       "      <td>0.706376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1476</td>\n",
       "      <td>767</td>\n",
       "      <td>0.658047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779</td>\n",
       "      <td>115</td>\n",
       "      <td>0.871365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1782</td>\n",
       "      <td>948</td>\n",
       "      <td>0.652747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_cluster_pos  initial_cluster_neg  initial_cluster_precision\n",
       "0                  626                   26                   0.960123\n",
       "1                  842                  350                   0.706376\n",
       "2                 1476                  767                   0.658047\n",
       "3                  779                  115                   0.871365\n",
       "4                 1782                  948                   0.652747"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_cluster = grant_to_cluster(train_pos_vector, 1, max_distance_each_cluster, centroids)\n",
    "false_cluster = grant_to_cluster(train_neg_vector, 1, max_distance_each_cluster, centroids)\n",
    "true_count, false_count = count_TPFP(centroids, true_cluster, false_cluster)\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# 각 클러스터에 포함된 positive 엔티티, negative 엔티티수로 각 클러스터에 대한 precision 지표 산출\n",
    "for cluster in range(len(centroids)):\n",
    "    TP = true_count[cluster] # True Positive : 클러스터 포함되어있는 positive 엔티티\n",
    "    FP = false_count[cluster] # False Positive : 클러스터에 포함되어있는 negative 엔티티\n",
    "    if (TP+FP) == 0:\n",
    "        precision = 0.0\n",
    "    else:\n",
    "        precision = TP / (TP+FP)\n",
    "    result_list.append([TP,FP,precision])\n",
    "\n",
    "# first_result_df\n",
    "pre_result_df = pd.DataFrame(result_list, columns=['initial_cluster_pos', \n",
    "                                                   'initial_cluster_neg', \n",
    "                                                   'initial_cluster_precision'])\n",
    "pre_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply the adaptive clustering method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimize delta for each clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimaldeltas each clusters : \n",
      " [1.   0.7  1.   1.   1.   1.   0.76 0.77 0.74 1.   0.79]\n"
     ]
    }
   ],
   "source": [
    "P, R, F1, TP, FN, FP, initial_TP = get_ada_matrics(train_pos_vector, train_neg_vector, \n",
    "                                                   max_distance_each_cluster, centroids)\n",
    "\n",
    "\n",
    "TP_list = TP[np.array(F1).argmax(0),list(range(TP.shape[1]))]\n",
    "\n",
    "#cluster의 f1 score가 최대가 되는 지점의 delta를 optimal delta로 선정\n",
    "optimal_deltas = np.array(F1).argmax(0)\n",
    "optimal_deltas = (optimal_deltas * 0.01)+0.6\n",
    "\n",
    "# positive entity수가 0인 cluster는 delta를 0으로 변환\n",
    "optimal_deltas = np.array([d if tp != 0 else 0 for d, tp in zip(optimal_deltas, TP_list)])\n",
    "\n",
    "print('optimaldeltas each clusters : \\n', optimal_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_cluster_pos</th>\n",
       "      <th>initial_cluster_neg</th>\n",
       "      <th>initial_cluster_precision</th>\n",
       "      <th>opt_delta</th>\n",
       "      <th>opt_TP</th>\n",
       "      <th>opt_FP</th>\n",
       "      <th>opt_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>626</td>\n",
       "      <td>26</td>\n",
       "      <td>0.960123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>626</td>\n",
       "      <td>26</td>\n",
       "      <td>0.960123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842</td>\n",
       "      <td>350</td>\n",
       "      <td>0.706376</td>\n",
       "      <td>0.7</td>\n",
       "      <td>749</td>\n",
       "      <td>208</td>\n",
       "      <td>0.782654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1476</td>\n",
       "      <td>767</td>\n",
       "      <td>0.658047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1476</td>\n",
       "      <td>767</td>\n",
       "      <td>0.658047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779</td>\n",
       "      <td>115</td>\n",
       "      <td>0.871365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>779</td>\n",
       "      <td>115</td>\n",
       "      <td>0.871365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1782</td>\n",
       "      <td>948</td>\n",
       "      <td>0.652747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1782</td>\n",
       "      <td>948</td>\n",
       "      <td>0.652747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_cluster_pos  initial_cluster_neg  initial_cluster_precision  \\\n",
       "0                  626                   26                   0.960123   \n",
       "1                  842                  350                   0.706376   \n",
       "2                 1476                  767                   0.658047   \n",
       "3                  779                  115                   0.871365   \n",
       "4                 1782                  948                   0.652747   \n",
       "\n",
       "   opt_delta  opt_TP  opt_FP  opt_precision  \n",
       "0        1.0     626      26       0.960123  \n",
       "1        0.7     749     208       0.782654  \n",
       "2        1.0    1476     767       0.658047  \n",
       "3        1.0     779     115       0.871365  \n",
       "4        1.0    1782     948       0.652747  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 구한 optimal delta를 cluster에 적용하여 각 cluster에 대한 precision, recall, TP, FP를 산출\n",
    "optimalP, optimalR, optimalTP, optimalFP = get_optimal_matrics(train_pos_vector, train_neg_vector, \n",
    "                                                               max_distance_each_cluster,centroids, \n",
    "                                                               optimal_deltas, initial_TP)\n",
    "\n",
    "matrics = []\n",
    "for m1, m2, m3, m4, m5 in zip(optimalP, optimalR,  optimalTP, optimalFP, optimal_deltas):\n",
    "    matrics.append([m1, m2, m3, m4, m5])\n",
    "    \n",
    "opt_delta_df = pd.DataFrame(matrics, columns=['opt_precision', 'opt_recall', 'opt_TP','opt_FP', 'opt_delta'])\n",
    "tmp_parse_df = opt_delta_df[['opt_delta','opt_TP','opt_FP', 'opt_precision']]\n",
    "train_result_df = pd.concat([pre_result_df, tmp_parse_df], axis = 1)\n",
    "train_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Error triple detection using test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test vectors from embedding model \n",
    "test_pos_vector = list(map(lambda x: (x,glove_dict[x]), test_pos_embedding))\n",
    "test_neg_vector = list(map(lambda x: (x,glove_dict[x]), test_neg_embedding))\n",
    "initial_TP = get_initial_TP(test_pos_vector, max_distance_each_cluster, centroids)\n",
    "\n",
    "# test 데이터의 embedding 벡터를 cluster에 할당하여 Precision, Recall 산출\n",
    "optimalP, optimalR, optimalTP, optimalFP = get_optimal_matrics(test_pos_vector, test_neg_vector, \n",
    "                                                               max_distance_each_cluster, centroids, \n",
    "                                                               optimal_deltas, initial_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_cluster_pos</th>\n",
       "      <th>initial_cluster_neg</th>\n",
       "      <th>initial_cluster_precision</th>\n",
       "      <th>opt_delta</th>\n",
       "      <th>opt_TP</th>\n",
       "      <th>opt_FP</th>\n",
       "      <th>opt_precision</th>\n",
       "      <th>Test_TP</th>\n",
       "      <th>Test_FP</th>\n",
       "      <th>Test_precision</th>\n",
       "      <th>Test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>626</td>\n",
       "      <td>26</td>\n",
       "      <td>0.960123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>626</td>\n",
       "      <td>26</td>\n",
       "      <td>0.960123</td>\n",
       "      <td>150</td>\n",
       "      <td>34</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842</td>\n",
       "      <td>350</td>\n",
       "      <td>0.706376</td>\n",
       "      <td>0.7</td>\n",
       "      <td>749</td>\n",
       "      <td>208</td>\n",
       "      <td>0.782654</td>\n",
       "      <td>144</td>\n",
       "      <td>172</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.837209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1476</td>\n",
       "      <td>767</td>\n",
       "      <td>0.658047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1476</td>\n",
       "      <td>767</td>\n",
       "      <td>0.658047</td>\n",
       "      <td>402</td>\n",
       "      <td>786</td>\n",
       "      <td>0.338384</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779</td>\n",
       "      <td>115</td>\n",
       "      <td>0.871365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>779</td>\n",
       "      <td>115</td>\n",
       "      <td>0.871365</td>\n",
       "      <td>181</td>\n",
       "      <td>112</td>\n",
       "      <td>0.617747</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1782</td>\n",
       "      <td>948</td>\n",
       "      <td>0.652747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1782</td>\n",
       "      <td>948</td>\n",
       "      <td>0.652747</td>\n",
       "      <td>484</td>\n",
       "      <td>928</td>\n",
       "      <td>0.342776</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_cluster_pos  initial_cluster_neg  initial_cluster_precision  \\\n",
       "0                  626                   26                   0.960123   \n",
       "1                  842                  350                   0.706376   \n",
       "2                 1476                  767                   0.658047   \n",
       "3                  779                  115                   0.871365   \n",
       "4                 1782                  948                   0.652747   \n",
       "\n",
       "   opt_delta  opt_TP  opt_FP  opt_precision  Test_TP  Test_FP  Test_precision  \\\n",
       "0        1.0     626      26       0.960123      150       34        0.815217   \n",
       "1        0.7     749     208       0.782654      144      172        0.455696   \n",
       "2        1.0    1476     767       0.658047      402      786        0.338384   \n",
       "3        1.0     779     115       0.871365      181      112        0.617747   \n",
       "4        1.0    1782     948       0.652747      484      928        0.342776   \n",
       "\n",
       "   Test_recall  \n",
       "0     1.000000  \n",
       "1     0.837209  \n",
       "2     1.000000  \n",
       "3     1.000000  \n",
       "4     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrics = []\n",
    "for m1, m2, m3, m4, m5 in zip(optimalP, optimalR, optimalTP, optimalFP, optimal_deltas):\n",
    "    matrics.append([m1, m2, m3, m4, m5])\n",
    "    \n",
    "output_df = pd.DataFrame(matrics, columns=['precision', 'recall', 'TP','FP', 'delta'])\n",
    "tmp_output_df = output_df[['TP','FP', 'precision', 'recall']]\n",
    "tmp_output_df.columns = ['Test_TP','Test_FP', 'Test_precision', 'Test_recall']\n",
    "\n",
    "train_test_df = pd.concat([train_result_df, tmp_output_df], axis = 1)\n",
    "train_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP :  4870\n",
      "FP :  3847\n",
      "precision :  0.5586784444189514\n",
      "recall :  0.974\n",
      "F1 :  0.7100677990814318\n",
      "\n",
      "Detected 1153 error triples\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대한 error detection결과 및 precision, recall, F1 score 산출\n",
    "new_TP = sum(train_test_df['Test_TP'].values)\n",
    "new_FP = sum(train_test_df['Test_FP'].values)\n",
    "\n",
    "new_precision = new_TP / (new_TP + new_FP)\n",
    "new_recall = new_TP / len(test_pos_embedding)\n",
    "new_f1 = (2*new_precision*new_recall) / (new_precision+new_recall)\n",
    "\n",
    "print('TP : ', new_TP)\n",
    "print('FP : ', new_FP)\n",
    "print('precision : ', new_precision)\n",
    "print('recall : ', new_recall)\n",
    "print('F1 : ', new_f1)\n",
    "\n",
    "print(f'\\nDetected {len(test_neg_embedding) - new_FP} error triples')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
